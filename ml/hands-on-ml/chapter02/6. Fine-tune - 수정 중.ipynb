{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a5b85b6-2b9b-436c-9e20-09d5974f6688",
   "metadata": {},
   "source": [
    "# Fine-Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83117d41-f4fd-4aaa-9e2f-153b38c98825",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/housing_prepared.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m housing_prepared = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/housing_prepared.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m housing_labels = joblib.load(\u001b[33m\"\u001b[39m\u001b[33mdata/housing_labels.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m housing = joblib.load(\u001b[33m\"\u001b[39m\u001b[33mdata/housing_raw.pkl\u001b[39m\u001b[33m\"\u001b[39m) \n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ML\\env\\Lib\\site-packages\\joblib\\numpy_pickle.py:735\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    733\u001b[39m         obj = _unpickle(fobj, ensure_native_byte_order=ensure_native_byte_order)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[32m    737\u001b[39m             fobj,\n\u001b[32m    738\u001b[39m             validated_mmap_mode,\n\u001b[32m    739\u001b[39m         ):\n\u001b[32m    740\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    741\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    742\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    743\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/housing_prepared.pkl'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "housing_prepared = joblib.load(\"data/housing_prepared.pkl\")\n",
    "housing_labels = joblib.load(\"data/housing_labels.pkl\")\n",
    "housing = joblib.load(\"data/housing_raw.pkl\") \n",
    "strat_train_set = joblib.load(\"data/strat_train_set.pkl\")\n",
    "strat_test_set = joblib.load(\"data/strat_test_set.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4976af8e-1629-46f8-9eff-c211a9028516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):  # 재정의\n",
    "    def __init__(self, attribute_names):  # 선택할 열 이름 목록을 초기화\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):  # fit 메서드 (여기선 학습 필요 없음)\n",
    "        return self\n",
    "    def transform(self, X):  # 지정된 열만 NumPy 배열 형태로 추출하여 반환\n",
    "        return X[self.attribute_names] # .values 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8352e136-c415-4940-9b56-b39742bbab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin  # 재정의\n",
    "\n",
    "# 열 인덱스 설정\n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6  # 순서대로 total_rooms, total_bedrooms, population, households 열의 인덱스\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):  # 파생 특성 생성용 사용자 정의 변환기 클래스 정의\n",
    "    def __init__(self, add_bedrooms_per_room=True):  # bedrooms_per_room 특성을 추가할지 여부를 설정하는 하이퍼파라미터\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):  # fit 메서드는 아무 작업 없이 self 반환 (필수 메서드)\n",
    "        return self\n",
    "    def transform(self, X, y=None):  # transform 메서드에서 새로운 파생 특성들을 계산하여 기존 데이터에 추가\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]  # 세 개의 파생 특성 추가\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]  # 두 개의 파생 특성만 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6ec7e-4e99-4d35-a1cd-0a4eb0471009",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = joblib.load(\"models/full_pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30801d33-8c20-4022-aed3-a2922d17b719",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cf070d-74cd-4c7d-856a-e7926f1a1cc3",
   "metadata": {},
   "source": [
    "하이퍼파라미터를 손으로 하나씩 조정하면서 좋은 조합을 찾는 대신 \n",
    "Scikit-Learn의 `GridSearchCV` 사용\n",
    ">이 도구에 어떤 하이퍼파라미터들을 실험할지,  \n",
    ">그리고 각 하이퍼파라미터마다 어떤 값을 시도할지를 알려주기만 하면  \n",
    ">모든 가능한 하이퍼파라미터 조합을 교차 검증을 통해 평가해 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d41ea-c594-4188-8c3a-a31d8a4fe3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV  # 하이퍼파라미터 튜닝을 위한 GridSearchCV 임포트\n",
    "from sklearn.ensemble import RandomForestRegressor  # 랜덤 포레스트 회귀 모델 임포트\n",
    "\n",
    "param_grid = [  # 탐색할 하이퍼파라미터 조합 정의\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor()  # 모델 객체 생성\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,  # 그리드 탐색 객체 생성\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "\n",
    "grid_search.fit(housing_prepared, housing_labels)  # 전체 훈련 세트로 학습 및 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c5456-fff5-457d-94da-a64b00fd22cc",
   "metadata": {},
   "source": [
    "어떤 하이퍼파라미터의 값을 전혀 모르겠을 때는,  \n",
    "10의 거듭제곱(또는 더 세밀하게 탐색하고 싶다면 더 작은 수)을 순서대로 시도해보는 것이 간단한 접근법(이 예제에서 `n_estimators` 하이퍼파라미터)\n",
    "\n",
    "이 `param_grid`는 Scikit-Learn에게 첫 번째 딕셔너리에 지정된 `n_estimators`와 `max_features` 하이퍼파라미터 값의   \n",
    "모든 3 × 4 = 12가지 조합을 먼저 평가하라고 지시(이 하이퍼파라미터들 의미는 7장에서)  \n",
    "그런 다음, 두 번째 딕셔너리에 있는 하이퍼파라미터 조합 2 × 3 = 6가지를 평가하는데,   \n",
    "이때는 기본값인 `bootstrap=True` 대신 `bootstrap=False`로 설정해서 진행  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825dca66-957b-4e83-83e7-77a29e543aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_  # 가장 좋은 하이퍼파라미터 조합 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e258d9-af1a-47ce-ae33-3ce0b655fcbb",
   "metadata": {},
   "source": [
    "6과 30은 평가된 값들 중 최대값이므로, 더 높은 값을 사용해 다시 탐색해보는 것이 좋음(점수가 계속해서 개선될 수 있기 때문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c4bae6-2b12-4429-a404-cbcf9e8164d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_  # 가장 성능이 좋은 모델 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e284560-06e7-4759-b9bb-0ed2d2622011",
   "metadata": {},
   "source": [
    "GridSearchCV가 refit=True로 초기화되면(기본값),  \n",
    "교차 검증을 통해 최적의 추정기를 찾은 후 전체 학습 세트로 다시 훈련  \n",
    "이는 일반적으로 좋은 방법인데, 더 많은 데이터를 제공하면 성능이 향상될 가능성이 높기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40aa5a-9036-4477-8c67-9b98f0d623ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_  # 교차 검증 결과 저장\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)  # RMSE와 하이퍼파라미터 조합 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5021cca-3e80-4dba-9b14-aeb499a7d1fa",
   "metadata": {},
   "source": [
    "이 예제에서는 `max_features` 하이퍼파라미터를 6으로, `n_estimators` 하이퍼파라미터를 30으로 설정함으로써 최적의 해를 얻음  \n",
    "이 조합의 RMSE 점수는 50,159로, 이전에 기본 하이퍼파라미터 값을 사용했을 때의 점수인 50,182보다 약간 더 좋음???\n",
    "\n",
    "데이터 준비 단계 중 일부도 하이퍼파라미터로 다룰 수 있다는 점을 잊지 말아야 함\n",
    ">예를 들어, 그리드 서치를 통해 확신이 없던 특성(예: `CombinedAttributesAdder` 변환기의 `add_bedrooms_per_room` 하이퍼파라미터)을 추가할지 말지를 자동으로 찾아낼 수 있음  \n",
    ">이와 유사하게 이상치 처리, 결측 특성 처리, 특성 선택 등에도 최적의 방식을 자동으로 찾아내는 데 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d651e8-dbe3-4b28-9917-483832376012",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1cdd2b-f9b2-43eb-a367-572dd08d7757",
   "metadata": {},
   "source": [
    "## Randomized Search(랜덤 탐색)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d061fcf8-2c20-4e11-b290-262758b42c15",
   "metadata": {},
   "source": [
    "그리드 서치 방식은 앞선 예제처럼 비교적 적은 수의 조합을 탐색할 때는 괜찮지만,  \n",
    "하이퍼파라미터 탐색 공간이 클 경우에는 `RandomizedSearchCV`를 사용하는 것이 더 나은 경우가 많음  \n",
    "이 클래스는 `GridSearchCV`와 거의 같은 방식으로 사용할 수 있지만, 가능한 모든 조합을 시도하는 대신,   \n",
    "각 반복에서 하이퍼파라미터마다 임의의 값을 선택해 지정된 수의 무작위 조합을 평가함  \n",
    "\n",
    "장점  \n",
    "1. 예를 들어 랜덤 탐색을 1,000회 반복하도록 설정하면, 각 하이퍼파라미터에 대해 1,000개의 서로 다른 값을 탐색하게 됨\n",
    "(그리드 서치 방식에서는 하이퍼파라미터당 몇 개의 값만 시도됨)  \n",
    "2. 반복 횟수만 설정함으로써, 하이퍼파라미터 탐색에 얼마만큼의 계산 자원을 할당할지 더 쉽게 제어할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee62db28-0966-47e4-a787-336cb2268411",
   "metadata": {},
   "source": [
    "## Ensemble Methods(앙상블 기법)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38db6204-b877-42ff-8dc0-dd44e382d1b9",
   "metadata": {},
   "source": [
    "시스템을 미세 조정하는 또 다른 방법 -> 성능이 좋은 여러 모델을 결합하는 것  \n",
    "이 집단(또는 “앙상블”)은 개별 모델 중 가장 좋은 것보다도 성능이 더 좋을 때가 많음  \n",
    "(`Random Forest`가 개별 `Decision Tree`보다 더 좋은 성능을 보이는 것처럼)  \n",
    "특히 개별 모델들이 서로 매우 다른 유형의 오류를 범할 때 효과가 큼\n",
    "\n",
    "이 주제는 7장에서 더 자세히 다뤄짐\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88536a7e-02f2-4a47-9724-a4a7ed85600d",
   "metadata": {},
   "source": [
    "## Analyze the Best Models and Their Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f06e0-6d97-4954-bd85-4d228107c4e5",
   "metadata": {},
   "source": [
    "최고의 모델들을 살펴보면 문제에 대한 좋은 통찰을 얻는 경우가 많음  \n",
    "예를 들어, `RandomForestRegressor`는 정확한 예측을 위해 각 특성이 얼마나 중요한지를 나타내는 상대적 중요도를 제공할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ffc72e-93c0-477b-bad7-4a7e95b87616",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_  # 특성 중요도 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18974313-5c67-4368-9ebf-ead8bcca2602",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e333d1-767b-491e-8819-a59b8e95dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "cat_encoder = OneHotEncoder(sparse_output=False)\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "\n",
    "cat_one_hot_attribs = list(cat_encoder.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66270f00-fa76-461c-89af-02ed6762ddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 열만 추출하고 열 이름 리스트 저장\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "num_attribs = list(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ea2431-d98e-4fe5-827e-a07bb6297029",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]  # 파생 변수 이름\n",
    "cat_one_hot_attribs = list(cat_encoder.get_feature_names_out())  # 원-핫 인코딩된 범주형 변수 이름\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs  # 전체 특성 이름 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55472b50-0728-4747-bfe6-9fa51cc4ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(feature_importances, attributes), reverse=True)  # 특성 중요도 내림차순 정렬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ad446-97dd-4ff5-ade1-ec1169152635",
   "metadata": {},
   "source": [
    "이 정보를 바탕으로 덜 유용한 특성들을 제거해볼 수도 있음  \n",
    "(예: `ocean_proximity` 카테고리 중 실제로 유용한 것은 하나뿐인 것 같으므로 나머지는 제거해볼 수 있음)  \n",
    "또한 시스템이 어떤 구체적인 오류를 범하는지도 살펴보고, 왜 그런 오류가 발생하는지,  \n",
    "그리고 이를 어떻게 해결할 수 있을지 고민해봐야 함(추가적인 특성을 더하거나, 정보가 없는 특성을 제거하거나, 이상치를 정리하는 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78885be7-0e5f-4011-a2e4-8c3d58264b09",
   "metadata": {},
   "source": [
    "## Evaluate Your System on the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be92bf39-02b4-43b6-ba4b-41e2d5ee181f",
   "metadata": {},
   "source": [
    "최종 모델을 테스트 세트에서 평가\n",
    "- 테스트 세트에서 입력값과 레이블을 가져오고, \n",
    "- 전체 파이프라인에서 transform()을 호출해 데이터를 변환한 다음(테스트 세트를 학습시키지 않기 위해 fit_transform()이 아니라 transform()을 호출해야), \n",
    "- 테스트 세트에서 최종 모델을 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8ae4b0-5ea0-4df0-852f-8c1e0167d5e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error  # RMSE 계산을 위한 모듈 임포트\n",
    "\n",
    "final_model = grid_search.best_estimator_  # 최종 모델 지정\n",
    "\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)  # 테스트 입력 특성\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()  # 테스트 타깃 레이블\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)  # 전처리 파이프라인 적용\n",
    "final_predictions = final_model.predict(X_test_prepared)  # 예측 수행\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)  # MSE 계산\n",
    "final_rmse = np.sqrt(final_mse)  # RMSE 계산\n",
    "print(final_rmse)  # RMSE 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4914a09e-39e7-471c-bf36-32e391498345",
   "metadata": {},
   "source": [
    "어떤 경우에는 일반화 오차에 대한 이러한 점 추정값만으로는 실제로 모델을 배포할지 확신하기에 충분하지 않을 수 있다. \n",
    "예를 들어, 현재 운영 중인 모델보다 단지 0.1%만 더 나은 경우라면, 이 추정값이 얼마나 정확한지를 알고 싶을 수도 있다.\n",
    "\n",
    "이를 위해 `scipy.stats.t.interval()`을 사용해 일반화 오차에 대한 95% 신뢰 구간을 계산할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79815aa2-a977-4eb8-9bdc-efd9b9b71a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(grid_search, \"models/grid_search.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0676b232-b4e8-42b5-bc5c-51d922984b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
