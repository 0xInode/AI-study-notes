
## 선형 회귀 모델을 학습시키는 두 가지 방법

 - 훈련 세트에 가장 잘 맞는 모델 파라미터를 직접 계산하는 ‘직접적(폐쇄형)’ 수식을 사용하는 방법(즉, 훈련 세트에 대한 비용 함수를 최소화하는 파라미터를 계산)

 - 경사 하강법(Gradient Descent, GD)이라 불리는 반복적 최적화 방식을 사용하는 방법  
> 이 방식은 모델 파라미터를 점진적으로 조정하여 훈련 세트에 대한 비용 함수를 최소화하며,  
> 결국 첫 번째 방법과 동일한 파라미터에 수렴


## 다항 회귀
이 모델은 비선형 데이터셋에도 잘 맞출 수 있는 보다 복잡한 모델  
다항 회귀는 선형 회귀보다 더 많은 파라미터를 가지므로 훈련 데이터에 과적합될 가능성이 더 큼  
-> 따라서 과적합 여부를 판단하는 데 도움이 되는 학습 곡선, 이어서 과적합 위험을 줄이기 위한 여러 가지 정규화 기법들 참고

## 로지스틱 회귀

## 소프트맥스 회귀
