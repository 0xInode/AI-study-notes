# Part I. The Fundamentals of Machine Learning
Chapter 1. The Machine Learning Landscape

🔹 머신러닝은 더 이상 미래의 기술이 아니다

많은 사람들이 머신러닝을 로봇이나 터미네이터처럼 상상하지만, 이미 일상에 깊이 적용된 기술이다.  
대표적 초기 사례: 스팸 필터 (1990년대 등장, 현재 대부분 자동 필터링됨)  
이후 수백 가지 ML 응용 프로그램이 추천 시스템, 음성 검색 등 다양한 서비스에서 사용됨  

🔹 머신러닝의 정의
간단한 정의:  
머신러닝은 데이터를 통해 컴퓨터가 학습하게 만드는 기술이다.  
Arthur Samuel (1959):  
“명시적으로 프로그래밍하지 않고도 컴퓨터에 학습 능력을 부여하는 연구 분야”  
Tom Mitchell (1997):  
컴퓨터가 경험 E를 통해 작업 T에서의 성능 P를 향상시킬 때, 학습했다고 말한다.  

예시: 스팸 필터  
T (작업): 이메일 스팸 분류  
E (경험): 스팸/정상 이메일의 학습 데이터  
P (성능): 정확도 (accuracy)  
→ 위 조건을 만족해야 ‘학습’이라고 부를 수 있음  

🔹 단순히 데이터가 많다고 "학습"한 건 아님  
예: 위키피디아를 다운받았다고 해서 컴퓨터가 "더 똑똑해진 것"은 아님  
학습이란, 특정 작업에 대한 성능 향상을 의미해야 함  

🔹 이 장에서 다루는 주요 주제  
머신러닝의 정의 및 필요성  
지도학습 vs 비지도학습 등 주요 유형 소개  
머신러닝 프로젝트의 전반적인 흐름  
모델 평가와 성능 향상 방법  
ML 관련 기본 용어와 개념 정리  

 Why Use Machine Learning? (왜 머신러닝을 사용하는가)  
🔹 전통적인 프로그래밍 방식의 한계  
스팸 필터를 전통적인 방식으로 만들려면:  
스팸에 자주 등장하는 단어나 패턴을 수작업으로 분석  
각 패턴마다 규칙을 작성  
테스트 후 규칙 추가/수정 반복  
이런 방식은 복잡하고 유지보수 어려움, 변화에 민감하지 않음  

🔹 머신러닝 방식의 장점  
스팸 메일과 일반 메일을 비교하며 자동으로 특징을 학습함  
규칙을 사람이 직접 만들 필요 없음 → 코드가 짧고 정확도 높음  
환경 변화에 자동 적응 가능  
→ 예: “4U”를 피해서 “For U”로 바꾸면, ML 모델이 이를 자동으로 학습함  
복잡하거나 기존 알고리즘이 없는 문제에 강력함  
→ 예: 음성 인식, 이미지 분석  

🔹 ML은 인간의 학습에도 도움  
학습된 모델을 분석하여 새로운 인사이트 도출 가능  
→ 예: 스팸 필터가 어떤 단어를 스팸으로 판단하는지 분석 가능  
데이터 마이닝(data mining): 대량의 데이터에서 숨겨진 패턴을 발견  

✅ 머신러닝이 적합한 문제 유형  
규칙이 너무 많거나 복잡한 문제  
기존 방식으로는 해결이 어려운 문제  
데이터나 환경이 자주 바뀌는 문제  
숨은 패턴이나 인사이트가 필요한 문제  


## 주요 개념  

- 머신러닝 정의: 시스템이 명시적 프로그래밍 없이 학습하는 능력  
- 유형
  - 지도학습 (Supervised Learning)
  - 비지도학습 (Unsupervised Learning)
  - 강화학습 (Reinforcement Learning)
  - 준지도학습 (Semi-supervised Learning)

분류 기준 1️⃣: 지도 학습 vs 비지도 학습  
유형	설명	예시  
Supervised Learning	정답(라벨)이 있는 데이터를 학습	이메일 분류 (스팸/햄), 가격 예측  
Unsupervised Learning	정답 없이 데이터 구조 탐색	군집화, 차원 축소  
Semi-supervised Learning	일부만 라벨이 있음	대규모 라벨링 어려운 경우  
Reinforcement Learning	보상을 통해 학습	게임, 로봇 제어 등  

분류 기준 2️⃣: 배치 학습 vs 온라인 학습
유형	설명  
Batch Learning	한 번에 전체 데이터를 학습  
Online Learning	데이터를 한 번에 하나씩 또는 작은 묶음으로 학습 (실시간 학습 가능)  

분류 기준 3️⃣: Instance-based vs Model-based Learning
유형	설명  
Instance-based	학습 데이터를 저장 → 새 데이터와 비교  
Model-based	학습 데이터로 일반화된 모델을 만들어 예측 수행  


🔹 Supervised Learning (지도 학습)
정답(label)이 포함된 데이터로 학습  
예시: 스팸 필터 (스팸/햄 라벨 포함)  
주요 작업  
분류 (classification): 이메일이 스팸인지 아닌지  
회귀 (regression): 주어진 특성(주행 거리, 나이 등)으로 자동차 가격 예측  
용어:  
Attribute: 데이터 속성 (예: "Mileage")  
Feature: 일반적으로 속성과 그 값 (예: "Mileage = 15,000")  
알고리즘 예시:  
k-최근접 이웃 (k-Nearest Neighbors)  
선형 회귀 (Linear Regression)  
로지스틱 회귀 (Logistic Regression)  
SVM (Support Vector Machines)  
결정 트리 & 랜덤 포레스트  
신경망 (Neural Networks)  

🔹 Unsupervised Learning (비지도 학습)  
라벨이 없는 데이터로 학습  
목표: 데이터의 패턴, 구조 발견  
주요 작업:  
군집화 (Clustering): 유사한 데이터 그룹 찾기  
예: 방문자 그룹 분류  
알고리즘: k-Means, HCA, EM  
시각화 / 차원 축소  
데이터 구조를 2D/3D로 시각화  
알고리즘: PCA, Kernel PCA, LLE, t-SNE  
이상 탐지 (Anomaly Detection): 정상과 다른 이상한 데이터 탐지  
예: 신용카드 사기 탐지  
연관 규칙 학습 (Association Rule Learning)  
속성 간의 관계 찾기 (예: BBQ 소스 + 칩 → 스테이크 구매)  

📘 Semisupervised Learning (준지도 학습)  
대부분은 라벨이 없고, 일부만 라벨이 있는 데이터 사용  
예: Google Photos에서 얼굴 클러스터링 → 일부 사진에 이름만 지정해주면 전체 인식 가능  
보통 지도 + 비지도 알고리즘의 조합  
예: Deep Belief Networks는 RBM(비지도)을 쌓고, 그 위에 지도 학습 적용  

📘 Reinforcement Learning (강화 학습)  
학습자(에이전트)가 환경을 관찰하고, 행동을 선택하며, 보상 또는 패널티를 받음  
목표: 장기적으로 최대 보상을 얻는 전략(Policy)을 학습  
예:  
로봇이 걷는 방법 학습  
AlphaGo: 수백만 경기 분석 + 자가 대국을 통해 전략 학습  

📘 Batch Learning (배치 학습)  
전체 데이터로 한 번에 학습 → 이후 더 이상 학습하지 않음  
오프라인에서 훈련하고, 이후 프로덕션에 적용  
새 데이터에 적응하려면 전체 데이터로 다시 훈련해야 함  
자동화 가능하지만, 데이터가 많거나 자주 바뀌면 비효율적이고 비용이 큼  

📘 Online Learning (온라인 학습)  
데이터를 하나씩 또는 미니배치 단위로 점진적으로 학습  
장점: 실시간 데이터 처리 가능  
자원이 적은 환경(스마트폰 등)에 적합  
매우 큰 데이터셋도 처리 가능 (out-of-core learning)  
주의점: 학습률(learning rate) 조절 중요  
높으면 빠르게 적응하지만 오래된 데이터는 쉽게 잊음  
낮으면 느리게 학습하지만 더 안정적  
나쁜 데이터가 들어오면 성능 저하 위험  
이상 데이터 감지, 성능 모니터링 필요  

🔹 Instance-Based Learning 기억 기반 학습  
학습 데이터를 그대로 저장하고, 유사도 측정을 통해 새로운 데이터를 처리  
예: 스팸 필터가 이전 스팸과 유사한 이메일을 탐지  
유사도 측정 예시: 두 이메일 간 공통 단어 수  
핵심: 기억된 예제들과의 거리 기반 예측  

🔹 Model-Based Learning  
데이터를 일반화할 수 있는 모델을 생성  
예시: 여러 국가의 GDP 대비 삶의 만족도 데이터 수집  
선형 모델 선택 (삶의 만족도 = θ₀ + θ₁ × GDP)  
모델 훈련: 파라미터 θ₀, θ₁ 결정 (비용 함수 최소화)  
훈련된 모델로 새로운 데이터 예측 (예: 키프로스의 삶의 만족도 추정)  

Python 코드 예시:  
LinearRegression() 모델로 훈련  
fit()으로 모델 학습  
predict()로 예측 수행  
비교 예시:  
k-최근접 이웃 회귀 (k-NN Regression):  
GDP가 비슷한 나라들의 만족도 평균값 사용 (k=3)  


📘 Main Challenges of Machine Learning  
🔹 문제 1: 나쁜 데이터  
1. 훈련 데이터 부족  
머신러닝은 많은 데이터가 필요  
간단한 문제도 수천 개, 복잡한 문제는 수백만 개의 예시 필요  

2. 대표성 없는 훈련 데이터  
훈련 데이터가 일반화 대상과 유사해야 함  
예: 특정 국가가 빠진 상태에서 학습한 모델은 부정확  
대표성 없는 샘플은 예측력 저하 → 샘플링 바이어스 발생  
예시: 1936년 미국 대선 여론조사 실패 (전화기 소유자만 대상)  

3. 품질이 낮은 데이터  
오류, 이상치, 노이즈가 많으면 학습 방해  
데이터 정제 작업이 중요  
이상치는 제거하거나 수정   
결측치는 무시, 대체, 혹은 별도 처리  

4. 무관한 특성  
관련 없는 특성이 많으면 학습 성능 저하  
특성 엔지니어링(feature engineering) 필요:  
특성 선택 (유용한 것만 사용)  
특성 추출 (기존 특성 조합)  
새로운 특성 생성  

🔹 문제 2: 나쁜 알고리즘  
1. 과적합 (Overfitting)  
모델이 훈련 데이터에 너무 맞춰져서 일반화 성능 저하  
예: 고차 다항 모델이 훈련 데이터는 잘 맞추지만, 새로운 데이터엔 부정확  
해결 방법:  
더 단순한 모델 사용  
특성 수 줄이기  
훈련 데이터 확장  
데이터 정제  
정규화(Regularization) 적용  
정규화는 모델을 단순화해 과적합을 줄이는 기법  
정규화 정도는 하이퍼파라미터로 조절  

2. 과소적합 (Underfitting)  
모델이 너무 단순해서 데이터 구조를 제대로 학습하지 못함  
예: 현실은 복잡한데 선형 모델만 사용한 경우  
해결 방법:  
더 복잡한 모델 선택  
더 좋은 특성 제공  
모델 제약 완화 (예: 정규화 줄이기)  

📘 Testing and Validating  
🔹 모델의 일반화 성능 확인 방법  
모델이 새로운 데이터에 잘 작동하는지 확인하려면, 실제로 새로운 데이터에서 테스트해야 함  
바로 프로덕션에 적용하는 방법도 있지만, 결과가 나쁘면 사용자 불만 초래  

🔹 훈련 세트와 테스트 세트 분리  
데이터를 훈련 세트(예: 80%)와 테스트 세트(예: 20%)로 분할  
훈련은 훈련 세트로, 일반화 성능 평가는 테스트 세트로  
테스트 세트에서의 오류율 = 일반화 오류 (generalization error)  
훈련 오류는 낮고 일반화 오류가 높다면, 과적합(overfitting)  

🔹 모델 비교 및 하이퍼파라미터 튜닝 문제  
예: 선형 모델 vs 다항 모델 → 테스트 세트 성능 비교  
규제(regularization) 강도를 조절하고 싶을 때:  
여러 하이퍼파라미터 값으로 모델을 훈련 후 테스트 세트에서 가장 낮은 오류 선택  
문제: 테스트 세트에 맞춰 모델을 조정했기 때문에 일반화 성능이 왜곡될 수 있음  

🔹 검증 세트(Validation Set)의 도입  
해결책: 세 번째 데이터 세트(검증 세트) 도입  
훈련: 훈련 세트  
모델 선택: 검증 세트  
최종 평가: 테스트 세트  
교차 검증 (Cross-Validation): 훈련 세트를 여러 부분으로 나눠 효율적으로 검증  
모든 데이터 활용률 높임  

🔹 최종 모델 선택  
모델 및 하이퍼파라미터 확정 후:  
전체 훈련 세트로 모델을 재훈련  
테스트 세트로 최종 일반화 오류 측정  

🔹 No Free Lunch Theorem  
어떤 모델이 항상 더 좋다는 보장은 없음  
모든 모델은 데이터에 대한 가정을 내포함  
예: 선형 모델은 데이터가 선형일 것이라고 가정  
가정을 전혀 하지 않으면, 어느 모델이 좋은지 알 수 없음  
현실에서는 합리적인 가정을 바탕으로 몇 가지 모델을 평가  

📌 키워드  
Machine Learning, training data, test set, validation set, generalization error, supervised learning, unsupervised learning, semisupervised learning,   
Reinforcement Learning, classification, regression, feature, instance-based learning, model-based learning, overfitting, underfitting, regularization,   
hyperparameter, cross-validation, cost function, policy, No Free Lunch theorem.  


